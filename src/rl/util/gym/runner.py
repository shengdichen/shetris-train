# The Reinforcement-Learning Module of the Shetris-Project#
# Copyright (C) 2022 Shengdi 'shc' Chen (me@shengdichen.xyz)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.
#


import time
from typing import Any, Callable

import gym


class RunnerGym:
    """
    Given a gym environment:
    1.  check correct implementation
    2.  inspect the environment:
        0.  direct calling for the env's builtin-functions
        1.  the spaces
        2.  the wrappers
    3.  run the environment
        1.  step-level
        2.  episode-level

    """

    def __init__(self, env: gym.Env):
        self._env = env

    @property
    def env(self):
        return self._env

    @env.setter
    def env(self, value: gym.Env):
        self._env = value

    def run_reset(self) -> Any:
        """
        Reset, i.e., init the env

        :return:
        """

        # might also contain |info|
        obs_init = self.env.reset()
        print("-" * 10, "resetting", "-" * 10)
        print("[RESET] obs: {0}\n".format(obs_init))
        self.env.render()
        print("-" * 10, "END OF RESET", "-" * 10, "\n" * 2)

        return obs_init

    def exec_action(self, action: Any) -> tuple[Any, float, bool, dict]:
        """
        Wrapper for the step-function:
        1.  perform the provided action
        2.  rander the result afterwards

        :type action: the action to take
        :return: True if episode-over, False otherwise
        """

        # print("-" * 10, "stepping", "-" * 10)
        # print("[STEP] Action:{0}; leading to:".format(action))

        obs, reward, done, info = self.env.step(action)

        self.env.render()
        # print()
        # print(
        #     "[STEP] obs: {0}\n"
        #     "[STEP] reward: {1}\n"
        #     "[STEP] info: {2}".format(obs, reward, info)
        # )
        # print("-" * 10, "END OF STEP", "-" * 10, "\n" * 2)

        return obs, reward, done, info

    def run_step(
        self, action_generator: Callable[..., Any]
    ) -> tuple[Any, float, bool, dict]:
        """
        Run a step, with the action generated by some generator

        :param action_generator:
        :return:
        """

        action = action_generator()
        return self.exec_action(action)

    def run_episode(self, action_generator: Callable[..., Any]) -> None:
        """
        Run one episode:
        1.  reset (init) the env
        2.  run many steps, as long as not game-over
        ->  each step performed by the step_generator

        NOTE:
        1.  could also provide a max num-steps for the episode:
        ->  maximal number of time-steps (number of inputs) of an episode
            NOTE:
            if using random-inputs, this value should largely exceed the usual
            number of random-inputs before game-over

        :param action_generator:
        :return:
        """

        self.run_reset()

        step_num, done = 0, False
        while not done:
            # print("[STEP] Nr.: ", step_num)
            __, __, done, __ = self.run_step(action_generator)
            step_num += 1

            # time.sleep(0.05)

        print("Episode finished: {0} steps in total\n\n".format(step_num))
        time.sleep(3)

    def run_episodes(
        self, action_generator: Callable[..., Any], n_episodes: int
    ) -> None:
        """
        Run some episodes

        :param action_generator:
        :type n_episodes:
        :return:
        """

        print("Running env: ", self.env)

        for t in range(n_episodes):
            print("Episode Nr. {0}".format(t))
            self.run_episode(action_generator)

    def get_action_generator_random(self) -> Callable[..., Any]:
        """
        Provide the generator (function) that provides random actions

        :return:
        """

        return self.env.action_space.sample

    def run_step_random(self) -> tuple[Any, float, bool, dict]:
        """
        Run a step with the random generator

        :return:
        """

        return self.run_step(self.get_action_generator_random())

    def run_episode_random(self):
        """
        Run the episode,
        1.  each step performed randomly

        :return:
        """

        self.run_episode(self.get_action_generator_random())

    def run_episodes_random(self, n_episodes: int):
        """
        Run some episodes, each using random actions

        :param n_episodes:
        :return:
        """

        self.run_episodes(self.get_action_generator_random(), n_episodes)

    def run_close(self):
        """
        Inspect the close()

        :return:
        """

        print("Closing env... ")
        self.env.close()


def run_episodes_test():
    from gym.envs.classic_control.cartpole import CartPoleEnv

    env = CartPoleEnv()
    ins = RunnerGym(env)

    ins.run_episodes_random(5)


if __name__ == "__main__":
    pass
    run_episodes_test()
